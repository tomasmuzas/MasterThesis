{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreateTFDataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr49SIehMQb7"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7sGIIOUMaO9"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-fRJuNNMb9_"
      },
      "source": [
        "DATASET_NAME = \"CombinedDataset_Training\"\n",
        "GCS_OUTPUT = f'gs://tomasmuzasmaster2021/dataset/{DATASET_NAME}'\n",
        "GCS_PATTERN = f'{DATASET_NAME}/*/*.jpg'\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "CLASSES = [b'Spiral', b'Elliptical']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWSVm84i5UoF",
        "outputId": "33bd7a80-31ed-4722-9dda-dc5f46fa82b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw3wEGK7MgjU",
        "outputId": "7f58aeda-211b-4ec2-c75c-b4251c3ac117"
      },
      "source": [
        "%%bash -s \"$DATASET_NAME\"\n",
        "rsync -ah --progress drive/MyDrive/MasterThesis/Dataset/$1.zip $1.zip && unzip -q $1.zip"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "CombinedDataset_Training.zip\n",
            "\r         32.77K   0%    0.00kB/s    0:00:00  \r         55.67M   9%   52.18MB/s    0:00:10  \r        110.66M  18%   52.31MB/s    0:00:09  \r        210.80M  34%   66.62MB/s    0:00:05  \r        267.75M  43%   63.51MB/s    0:00:05  \r        364.74M  59%   72.98MB/s    0:00:03  \r        411.86M  67%   70.82MB/s    0:00:02  \r        545.69M  89%   78.76MB/s    0:00:00  \r        609.17M 100%   78.53MB/s    0:00:07 (xfr#1, to-chk=0/1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HCk-4rMMkVg"
      },
      "source": [
        "import math\n",
        "\n",
        "def decode_jpeg_and_label(filename):\n",
        "  bits = tf.io.read_file(filename)\n",
        "  image = tf.image.decode_jpeg(bits)\n",
        "  vals = tf.strings.split(tf.expand_dims(filename, axis=-1), sep='/')\n",
        "  label = vals.values[-2]\n",
        "  objid = tf.strings.regex_replace(vals.values[-1], \"(\\_repeated)?\\.jpg\", \"\")\n",
        "  return image, label, objid\n",
        "\n",
        "def recompress_image(image, label, objid):\n",
        "  image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)\n",
        "  return image, label, objid\n",
        "\n",
        "def _bytestring_feature(list_of_bytestrings):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
        "\n",
        "def _int_feature(list_of_ints): # int64\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
        "\n",
        "def _float_feature(list_of_floats): # float32\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
        "\n",
        "def to_tfrecord(tfrec_filewriter, img_bytes, label, objid):  \n",
        "  class_num = np.argmax(np.array(CLASSES)==label) # 'roses' => 2 (order defined in CLASSES)\n",
        "  one_hot_class = np.eye(len(CLASSES))[class_num]     # [0, 0, 1, 0, 0] for class #2, roses\n",
        "\n",
        "  feature = {\n",
        "      \"image\": _bytestring_feature([img_bytes]), # one image in the list\n",
        "      \"class\": _int_feature([class_num]),        # one class in the list\n",
        "      \n",
        "      \"label\":         _bytestring_feature([label]),          # fixed length (1) list of strings, the text label\n",
        "      \"objid\":         _bytestring_feature([objid]),          # fixed length (1) list of strings, the text label\n",
        "      \"one_hot_class\": _float_feature(one_hot_class.tolist()) # variable length  list of floats, n=len(CLASSES)\n",
        "  }\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh4_ZzsTMnOU"
      },
      "source": [
        "def create_tf_record_dataset(filenames, items_per_record):\n",
        "  dataset2 = filenames.map(decode_jpeg_and_label, num_parallel_calls=AUTO)\n",
        "  dataset3 = dataset2.map(recompress_image, num_parallel_calls=AUTO)\n",
        "  dataset3 = dataset3.batch(items_per_record) # sharding: there will be one \"batch\" of images per file\n",
        "\n",
        "  print(\"Writing TFRecords\")\n",
        "  for shard, (image, label, objid) in enumerate(dataset3):\n",
        "    # batch size used as shard size here\n",
        "    shard_size = image.numpy().shape[0]\n",
        "    # good practice to have the number of records in the filename\n",
        "    filename = GCS_OUTPUT + \"/{:02d}-{}.tfrec\".format(shard, shard_size)\n",
        "    \n",
        "    np_image = image.numpy()\n",
        "    np_label = label.numpy()\n",
        "    np_objid = objid.numpy()\n",
        "\n",
        "    with tf.io.TFRecordWriter(filename) as out_file:\n",
        "      for i in range(shard_size):\n",
        "        example = to_tfrecord(out_file,\n",
        "                              np_image[i], # re-compressed image: already a byte string\n",
        "                              np_label[i],\n",
        "                              np_objid[i])\n",
        "        out_file.write(example.SerializeToString())\n",
        "      print(\"Wrote file {} containing {} records\".format(filename, shard_size))\n",
        "  print(\"Done.\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuh6sM-vMo5Y",
        "outputId": "ae19bb8f-4ffb-41f2-9a96-fe702dc17dcd"
      },
      "source": [
        "number_of_items = len(tf.io.gfile.glob(GCS_PATTERN))\n",
        "print(number_of_items)\n",
        "filenames = tf.data.Dataset.list_files(GCS_PATTERN, seed=777)\n",
        "\n",
        "create_tf_record_dataset(filenames, 4096)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252928\n",
            "Writing TFRecords\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/00-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/01-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/02-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/03-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/04-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/05-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/06-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/07-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/08-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/09-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/10-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/11-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/12-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/13-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/14-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/15-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/16-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/17-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/18-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/19-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/20-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/21-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/22-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/23-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/24-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/25-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/26-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/27-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/28-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/29-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/30-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/31-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/32-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/33-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/34-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/35-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/36-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/37-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/38-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/39-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/40-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/41-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/42-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/43-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/44-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/45-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/46-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/47-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/48-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/49-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/50-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/51-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/52-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/53-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/54-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/55-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/56-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/57-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/58-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/59-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/60-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Training/61-3072.tfrec containing 3072 records\n",
            "Done.\n"
          ]
        }
      ]
    }
  ]
}