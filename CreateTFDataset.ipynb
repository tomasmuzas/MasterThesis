{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreateTFDataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr49SIehMQb7"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7sGIIOUMaO9"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-fRJuNNMb9_"
      },
      "source": [
        "DATASET_NAME = \"CombinedDataset_Test\"\n",
        "GCS_OUTPUT = f'gs://tomasmuzasmaster2021/dataset/{DATASET_NAME}'\n",
        "GCS_PATTERN = f'{DATASET_NAME}/*/*.jpg'\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "CLASSES = [b'Spiral', b'Elliptical']"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWSVm84i5UoF",
        "outputId": "358c82e2-7cb3-44bb-fc1d-6c924a222002"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw3wEGK7MgjU",
        "outputId": "eb505017-5b5c-4ece-f6e7-9d30ae94a685"
      },
      "source": [
        "%%bash -s \"$DATASET_NAME\"\n",
        "rsync -ah --progress drive/MyDrive/MasterThesis/Dataset/$1.zip $1.zip && unzip -q $1.zip"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "CombinedDataset_Test.zip\n",
            "\r         32.77K   0%    0.00kB/s    0:00:00  \r         24.94M  32%   23.42MB/s    0:00:02  \r         57.44M  75%   25.67MB/s    0:00:00  \r         75.85M 100%   30.99MB/s    0:00:02 (xfr#1, to-chk=0/1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HCk-4rMMkVg"
      },
      "source": [
        "import math\n",
        "\n",
        "def decode_jpeg_and_label(filename):\n",
        "  bits = tf.io.read_file(filename)\n",
        "  image = tf.image.decode_jpeg(bits)\n",
        "  vals = tf.strings.split(tf.expand_dims(filename, axis=-1), sep='/')\n",
        "  label = vals.values[-2]\n",
        "  objid = tf.strings.regex_replace(vals.values[-1], \"\\.jpg\", \"\")\n",
        "  return image, label, objid\n",
        "\n",
        "def recompress_image(image, label, objid):\n",
        "  image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)\n",
        "  return image, label, objid\n",
        "\n",
        "def _bytestring_feature(list_of_bytestrings):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
        "\n",
        "def _int_feature(list_of_ints): # int64\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
        "\n",
        "def _float_feature(list_of_floats): # float32\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
        "\n",
        "def to_tfrecord(tfrec_filewriter, img_bytes, label, objid):  \n",
        "  class_num = np.argmax(np.array(CLASSES)==label) # 'roses' => 2 (order defined in CLASSES)\n",
        "  one_hot_class = np.eye(len(CLASSES))[class_num]     # [0, 0, 1, 0, 0] for class #2, roses\n",
        "\n",
        "  feature = {\n",
        "      \"image\": _bytestring_feature([img_bytes]), # one image in the list\n",
        "      \"class\": _int_feature([class_num]),        # one class in the list\n",
        "      \n",
        "      \"label\":         _bytestring_feature([label]),          # fixed length (1) list of strings, the text label\n",
        "      \"objid\":         _bytestring_feature([objid]),          # fixed length (1) list of strings, the text label\n",
        "      \"one_hot_class\": _float_feature(one_hot_class.tolist()) # variable length  list of floats, n=len(CLASSES)\n",
        "  }\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh4_ZzsTMnOU"
      },
      "source": [
        "def create_tf_record_dataset(filenames, items_per_record):\n",
        "  dataset2 = filenames.map(decode_jpeg_and_label, num_parallel_calls=AUTO)\n",
        "  dataset3 = dataset2.map(recompress_image, num_parallel_calls=AUTO)\n",
        "  dataset3 = dataset3.batch(items_per_record) # sharding: there will be one \"batch\" of images per file\n",
        "\n",
        "  print(\"Writing TFRecords\")\n",
        "  for shard, (image, label, objid) in enumerate(dataset3):\n",
        "    # batch size used as shard size here\n",
        "    shard_size = image.numpy().shape[0]\n",
        "    # good practice to have the number of records in the filename\n",
        "    filename = GCS_OUTPUT + \"/{:02d}-{}.tfrec\".format(shard, shard_size)\n",
        "    \n",
        "    np_image = image.numpy()\n",
        "    np_label = label.numpy()\n",
        "    np_objid = objid.numpy()\n",
        "\n",
        "    with tf.io.TFRecordWriter(filename) as out_file:\n",
        "      for i in range(shard_size):\n",
        "        example = to_tfrecord(out_file,\n",
        "                              np_image[i], # re-compressed image: already a byte string\n",
        "                              np_label[i],\n",
        "                              np_objid[i])\n",
        "        out_file.write(example.SerializeToString())\n",
        "      print(\"Wrote file {} containing {} records\".format(filename, shard_size))\n",
        "  print(\"Done.\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuh6sM-vMo5Y",
        "outputId": "c04f45fb-4fa4-4fc7-f710-ea7dba81fbe8"
      },
      "source": [
        "number_of_items = len(tf.io.gfile.glob(GCS_PATTERN))\n",
        "print(number_of_items)\n",
        "filenames = tf.data.Dataset.list_files(GCS_PATTERN, seed=777)\n",
        "\n",
        "create_tf_record_dataset(filenames, 4096)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31594\n",
            "Writing TFRecords\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Test/00-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Test/01-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Test/02-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Test/03-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Test/04-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Test/05-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Test/06-4096.tfrec containing 4096 records\n",
            "Wrote file gs://tomasmuzasmaster2021/dataset/CombinedDataset_Test/07-2922.tfrec containing 2922 records\n",
            "Done.\n"
          ]
        }
      ]
    }
  ]
}